{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Корректность проверена на Python 3.6:**\n",
    "+ numpy 1.15.4\n",
    "+ pandas 0.23.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TV           85.854236\n",
       "Radio        14.846809\n",
       "Newspaper    21.778621\n",
       "Sales         5.217457\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "data.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[230.1,  44.5,  17.2, 151.5, 180.8,   8.7,  57.5, 120.2,   8.6,\n",
       "        199.8,  66.1, 214.7,  23.8,  97.5, 204.1, 195.4,  67.8, 281.4,\n",
       "         69.2, 147.3, 218.4, 237.4,  13.2, 228.3,  62.3, 262.9, 142.9,\n",
       "        240.1, 248.8,  70.6, 292.9, 112.9,  97.2, 265.6,  95.7, 290.7,\n",
       "        266.9,  74.7,  43.1, 228. , 202.5, 177. , 293.6, 206.9,  25.1,\n",
       "        175.1,  89.7, 239.9, 227.2,  66.9, 199.8, 100.4, 216.4, 182.6,\n",
       "        262.7, 198.9,   7.3, 136.2, 210.8, 210.7,  53.5, 261.3, 239.3,\n",
       "        102.7, 131.1,  69. ,  31.5, 139.3, 237.4, 216.8, 199.1, 109.8,\n",
       "         26.8, 129.4, 213.4,  16.9,  27.5, 120.5,   5.4, 116. ,  76.4,\n",
       "        239.8,  75.3,  68.4, 213.5, 193.2,  76.3, 110.7,  88.3, 109.8,\n",
       "        134.3,  28.6, 217.7, 250.9, 107.4, 163.3, 197.6, 184.9, 289.7,\n",
       "        135.2, 222.4, 296.4, 280.2, 187.9, 238.2, 137.9,  25. ,  90.4,\n",
       "         13.1, 255.4, 225.8, 241.7, 175.7, 209.6,  78.2,  75.1, 139.2,\n",
       "         76.4, 125.7,  19.4, 141.3,  18.8, 224. , 123.1, 229.5,  87.2,\n",
       "          7.8,  80.2, 220.3,  59.6,   0.7, 265.2,   8.4, 219.8,  36.9,\n",
       "         48.3,  25.6, 273.7,  43. , 184.9,  73.4, 193.7, 220.5, 104.6,\n",
       "         96.2, 140.3, 240.1, 243.2,  38. ,  44.7, 280.7, 121. , 197.6,\n",
       "        171.3, 187.8,   4.1,  93.9, 149.8,  11.7, 131.7, 172.5,  85.7,\n",
       "        188.4, 163.5, 117.2, 234.5,  17.9, 206.8, 215.4, 284.3,  50. ,\n",
       "        164.5,  19.6, 168.4, 222.4, 276.9, 248.4, 170.2, 276.7, 165.6,\n",
       "        156.6, 218.5,  56.2, 287.6, 253.8, 205. , 139.5, 191.1, 286. ,\n",
       "         18.7,  39.5,  75.5,  17.2, 166.8, 149.7,  38.2,  94.2, 177. ,\n",
       "        283.6, 232.1],\n",
       "       [ 37.8,  39.3,  45.9,  41.3,  10.8,  48.9,  32.8,  19.6,   2.1,\n",
       "          2.6,   5.8,  24. ,  35.1,   7.6,  32.9,  47.7,  36.6,  39.6,\n",
       "         20.5,  23.9,  27.7,   5.1,  15.9,  16.9,  12.6,   3.5,  29.3,\n",
       "         16.7,  27.1,  16. ,  28.3,  17.4,   1.5,  20. ,   1.4,   4.1,\n",
       "         43.8,  49.4,  26.7,  37.7,  22.3,  33.4,  27.7,   8.4,  25.7,\n",
       "         22.5,   9.9,  41.5,  15.8,  11.7,   3.1,   9.6,  41.7,  46.2,\n",
       "         28.8,  49.4,  28.1,  19.2,  49.6,  29.5,   2. ,  42.7,  15.5,\n",
       "         29.6,  42.8,   9.3,  24.6,  14.5,  27.5,  43.9,  30.6,  14.3,\n",
       "         33. ,   5.7,  24.6,  43.7,   1.6,  28.5,  29.9,   7.7,  26.7,\n",
       "          4.1,  20.3,  44.5,  43. ,  18.4,  27.5,  40.6,  25.5,  47.8,\n",
       "          4.9,   1.5,  33.5,  36.5,  14. ,  31.6,   3.5,  21. ,  42.3,\n",
       "         41.7,   4.3,  36.3,  10.1,  17.2,  34.3,  46.4,  11. ,   0.3,\n",
       "          0.4,  26.9,   8.2,  38. ,  15.4,  20.6,  46.8,  35. ,  14.3,\n",
       "          0.8,  36.9,  16. ,  26.8,  21.7,   2.4,  34.6,  32.3,  11.8,\n",
       "         38.9,   0. ,  49. ,  12. ,  39.6,   2.9,  27.2,  33.5,  38.6,\n",
       "         47. ,  39. ,  28.9,  25.9,  43.9,  17. ,  35.4,  33.2,   5.7,\n",
       "         14.8,   1.9,   7.3,  49. ,  40.3,  25.8,  13.9,   8.4,  23.3,\n",
       "         39.7,  21.1,  11.6,  43.5,   1.3,  36.9,  18.4,  18.1,  35.8,\n",
       "         18.1,  36.8,  14.7,   3.4,  37.6,   5.2,  23.6,  10.6,  11.6,\n",
       "         20.9,  20.1,   7.1,   3.4,  48.9,  30.2,   7.8,   2.3,  10. ,\n",
       "          2.6,   5.4,   5.7,  43. ,  21.3,  45.1,   2.1,  28.7,  13.9,\n",
       "         12.1,  41.1,  10.8,   4.1,  42. ,  35.6,   3.7,   4.9,   9.3,\n",
       "         42. ,   8.6],\n",
       "       [ 69.2,  45.1,  69.3,  58.5,  58.4,  75. ,  23.5,  11.6,   1. ,\n",
       "         21.2,  24.2,   4. ,  65.9,   7.2,  46. ,  52.9, 114. ,  55.8,\n",
       "         18.3,  19.1,  53.4,  23.5,  49.6,  26.2,  18.3,  19.5,  12.6,\n",
       "         22.9,  22.9,  40.8,  43.2,  38.6,  30. ,   0.3,   7.4,   8.5,\n",
       "          5. ,  45.7,  35.1,  32. ,  31.6,  38.7,   1.8,  26.4,  43.3,\n",
       "         31.5,  35.7,  18.5,  49.9,  36.8,  34.6,   3.6,  39.6,  58.7,\n",
       "         15.9,  60. ,  41.4,  16.6,  37.7,   9.3,  21.4,  54.7,  27.3,\n",
       "          8.4,  28.9,   0.9,   2.2,  10.2,  11. ,  27.2,  38.7,  31.7,\n",
       "         19.3,  31.3,  13.1,  89.4,  20.7,  14.2,   9.4,  23.1,  22.3,\n",
       "         36.9,  32.5,  35.6,  33.8,  65.7,  16. ,  63.2,  73.4,  51.4,\n",
       "          9.3,  33. ,  59. ,  72.3,  10.9,  52.9,   5.9,  22. ,  51.2,\n",
       "         45.9,  49.8, 100.9,  21.4,  17.9,   5.3,  59. ,  29.7,  23.2,\n",
       "         25.6,   5.5,  56.5,  23.2,   2.4,  10.7,  34.5,  52.7,  25.6,\n",
       "         14.8,  79.2,  22.3,  46.2,  50.4,  15.6,  12.4,  74.2,  25.9,\n",
       "         50.6,   9.2,   3.2,  43.1,   8.7,  43. ,   2.1,  45.1,  65.6,\n",
       "          8.5,   9.3,  59.7,  20.5,   1.7,  12.9,  75.6,  37.9,  34.4,\n",
       "         38.9,   9. ,   8.7,  44.3,  11.9,  20.6,  37. ,  48.7,  14.2,\n",
       "         37.7,   9.5,   5.7,  50.5,  24.3,  45.2,  34.6,  30.7,  49.3,\n",
       "         25.6,   7.4,   5.4,  84.8,  21.6,  19.4,  57.6,   6.4,  18.4,\n",
       "         47.4,  17. ,  12.8,  13.1,  41.8,  20.3,  35.2,  23.7,  17.6,\n",
       "          8.3,  27.4,  29.7,  71.8,  30. ,  19.6,  26.6,  18.2,   3.7,\n",
       "         23.4,   5.8,   6. ,  31.6,   3.6,   6. ,  13.8,   8.1,   6.4,\n",
       "         66.2,   8.7]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([data['TV'],data['Radio'],data['Newspaper']])\n",
    "y = np.array(data['Sales'])\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147.0425  23.264   30.554 ] [147.0425, 23.264000000000006, 30.553999999999995]\n"
     ]
    }
   ],
   "source": [
    "means, stds = X.mean(axis=1), X.std(axis=1)\n",
    "means1 = [X[0].mean(),X[1].mean(),X[2].mean()]\n",
    "print(means, means1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.70567244, -1.7309789 , -1.73470124, -1.71638951, -1.71239447,\n",
       "        -1.73586021, -1.72920636, -1.72065724, -1.73587385, -1.70980383,\n",
       "        -1.72803375, -1.70777222, -1.73380133, -1.72375238, -1.70921752,\n",
       "        -1.71040376, -1.72780196, -1.69867771, -1.72761107, -1.71696217,\n",
       "        -1.70726773, -1.70467709, -1.73524664, -1.70591787, -1.72855188,\n",
       "        -1.70120017, -1.71756211, -1.70430894, -1.7031227 , -1.72742018,\n",
       "        -1.69710969, -1.7216526 , -1.72379328, -1.70083203, -1.72399781,\n",
       "        -1.69740966, -1.70065478, -1.72686115, -1.73116979, -1.70595877,\n",
       "        -1.70943568, -1.71291259, -1.69701425, -1.70883575, -1.73362408,\n",
       "        -1.71317166, -1.7248159 , -1.70433621, -1.70606785, -1.72792467,\n",
       "        -1.70980383, -1.72335696, -1.70754043, -1.71214904, -1.70122744,\n",
       "        -1.70992654, -1.7360511 , -1.71847565, -1.70830398, -1.70831762,\n",
       "        -1.72975175, -1.70141833, -1.70441802, -1.72304336, -1.71917104,\n",
       "        -1.72763834, -1.73275144, -1.71805297, -1.70467709, -1.70748589,\n",
       "        -1.70989927, -1.72207528, -1.73339229, -1.71940283, -1.70794947,\n",
       "        -1.73474214, -1.73329684, -1.72061634, -1.73631016, -1.72122991,\n",
       "        -1.72662935, -1.70434985, -1.72677934, -1.72772015, -1.70793584,\n",
       "        -1.71070373, -1.72664299, -1.72195256, -1.72500679, -1.72207528,\n",
       "        -1.71873472, -1.73314686, -1.70736317, -1.70283637, -1.72240252,\n",
       "        -1.71478058, -1.7101038 , -1.71183543, -1.69754601, -1.718612  ,\n",
       "        -1.70672233, -1.69663247, -1.69884133, -1.71142639, -1.70456801,\n",
       "        -1.71824386, -1.73363771, -1.72472046, -1.73526027, -1.7022228 ,\n",
       "        -1.70625874, -1.70409078, -1.71308985, -1.7084676 , -1.72638392,\n",
       "        -1.72680661, -1.7180666 , -1.72662935, -1.71990732, -1.73440127,\n",
       "        -1.71778027, -1.73448308, -1.70650417, -1.72026183, -1.70575425,\n",
       "        -1.72515678, -1.73598292, -1.72611122, -1.70700866, -1.72892002,\n",
       "        -1.73695101, -1.70088657, -1.73590112, -1.70707684, -1.73201516,\n",
       "        -1.73046077, -1.7335559 , -1.6997276 , -1.73118342, -1.71183543,\n",
       "        -1.7270384 , -1.71063556, -1.70698139, -1.7227843 , -1.72392963,\n",
       "        -1.71791662, -1.70430894, -1.70388626, -1.73186517, -1.73095163,\n",
       "        -1.69877315, -1.72054816, -1.7101038 , -1.71368979, -1.71144002,\n",
       "        -1.73648742, -1.72424324, -1.7166213 , -1.73545116, -1.71908923,\n",
       "        -1.71352617, -1.7253613 , -1.71135821, -1.71475331, -1.72106629,\n",
       "        -1.7050725 , -1.7346058 , -1.70884938, -1.70767677, -1.6982823 ,\n",
       "        -1.73022898, -1.71461696, -1.734374  , -1.7140852 , -1.70672233,\n",
       "        -1.69929128, -1.70317724, -1.71383977, -1.69931855, -1.71446698,\n",
       "        -1.71569412, -1.70725409, -1.72938361, -1.69783234, -1.70244095,\n",
       "        -1.70909481, -1.7180257 , -1.71099007, -1.6980505 , -1.73449672,\n",
       "        -1.73166065, -1.72675207, -1.73470124, -1.71430336, -1.71663493,\n",
       "        -1.7318379 , -1.72420233, -1.71291259, -1.69837774, -1.70539974],\n",
       "       [-1.50459221, -1.49775307, -1.46766082, -1.48863421, -1.62769686,\n",
       "        -1.45398253, -1.52738937, -1.58757386, -1.66736391, -1.66508419,\n",
       "        -1.65049401, -1.56751236, -1.51690268, -1.64228704, -1.52693343,\n",
       "        -1.45945385, -1.51006353, -1.49638524, -1.58347037, -1.56796831,\n",
       "        -1.55064247, -1.65368561, -1.60444376, -1.59988433, -1.61948988,\n",
       "        -1.6609807 , -1.54334738, -1.60079621, -1.55337813, -1.60398781,\n",
       "        -1.54790681, -1.59760461, -1.67009957, -1.58575009, -1.67055551,\n",
       "        -1.65824505, -1.47723563, -1.45170281, -1.5552019 , -1.50504816,\n",
       "        -1.5752634 , -1.52465371, -1.55064247, -1.63863949, -1.55976133,\n",
       "        -1.57435151, -1.63180034, -1.48772232, -1.6048997 , -1.62359337,\n",
       "        -1.66280448, -1.63316817, -1.48681043, -1.46629299, -1.5456271 ,\n",
       "        -1.45170281, -1.5488187 , -1.58939763, -1.45079093, -1.54243549,\n",
       "        -1.66781985, -1.482251  , -1.60626753, -1.54197955, -1.48179506,\n",
       "        -1.634536  , -1.56477671, -1.61082696, -1.55155436, -1.47677968,\n",
       "        -1.53742012, -1.61173885, -1.52647748, -1.65094996, -1.56477671,\n",
       "        -1.47769157, -1.66964362, -1.54699492, -1.54061172, -1.64183109,\n",
       "        -1.5552019 , -1.65824505, -1.58438226, -1.47404403, -1.48088317,\n",
       "        -1.59304518, -1.55155436, -1.49182581, -1.56067322, -1.4589979 ,\n",
       "        -1.6545975 , -1.67009957, -1.52419777, -1.51051947, -1.61310668,\n",
       "        -1.53286069, -1.6609807 , -1.58119066, -1.48407477, -1.48681043,\n",
       "        -1.65733316, -1.51143136, -1.63088846, -1.5985165 , -1.52055022,\n",
       "        -1.46538111, -1.62678497, -1.67557088, -1.67511494, -1.55429001,\n",
       "        -1.63955138, -1.50368033, -1.60672347, -1.58301443, -1.46355733,\n",
       "        -1.51735862, -1.61173885, -1.67329117, -1.5086957 , -1.60398781,\n",
       "        -1.55474596, -1.57799906, -1.66599608, -1.51918239, -1.52966909,\n",
       "        -1.62313743, -1.49957684, -1.67693871, -1.45352658, -1.62222554,\n",
       "        -1.49638524, -1.66371636, -1.55292218, -1.52419777, -1.50094467,\n",
       "        -1.46264545, -1.4991209 , -1.54517115, -1.55884945, -1.47677968,\n",
       "        -1.59942838, -1.51553485, -1.5255656 , -1.65094996, -1.60945913,\n",
       "        -1.66827579, -1.64365487, -1.45352658, -1.49319364, -1.55930539,\n",
       "        -1.61356262, -1.63863949, -1.57070397, -1.4959293 , -1.58073472,\n",
       "        -1.62404931, -1.47860346, -1.67101145, -1.5086957 , -1.59304518,\n",
       "        -1.59441301, -1.51371108, -1.59441301, -1.50915165, -1.60991507,\n",
       "        -1.66143665, -1.5055041 , -1.65322967, -1.56933614, -1.62860874,\n",
       "        -1.62404931, -1.5816466 , -1.58529415, -1.64456675, -1.66143665,\n",
       "        -1.45398253, -1.53924389, -1.64137515, -1.66645202, -1.6313444 ,\n",
       "        -1.66508419, -1.65231778, -1.65094996, -1.48088317, -1.57982283,\n",
       "        -1.47130837, -1.66736391, -1.54608304, -1.61356262, -1.6217696 ,\n",
       "        -1.48954609, -1.62769686, -1.65824505, -1.4854426 , -1.51462296,\n",
       "        -1.66006882, -1.6545975 , -1.634536  , -1.4854426 , -1.63772761],\n",
       "       [-1.32456795, -1.37563411, -1.32435605, -1.34724047, -1.34745237,\n",
       "        -1.31227816, -1.42140295, -1.44661819, -1.46907883, -1.42627648,\n",
       "        -1.4199197 , -1.46272204, -1.33156041, -1.45594147, -1.37372707,\n",
       "        -1.35910647, -1.22963998, -1.35296158, -1.43242137, -1.43072623,\n",
       "        -1.35804701, -1.42140295, -1.36609893, -1.41568184, -1.43242137,\n",
       "        -1.42987866, -1.44449926, -1.42267431, -1.42267431, -1.3847455 ,\n",
       "        -1.37966007, -1.38940714, -1.40762992, -1.47056208, -1.45551769,\n",
       "        -1.45318687, -1.46060311, -1.37436275, -1.39682339, -1.40339206,\n",
       "        -1.40423963, -1.38919525, -1.46738368, -1.41525806, -1.37944818,\n",
       "        -1.40445153, -1.39555203, -1.43199759, -1.36546325, -1.39322121,\n",
       "        -1.39788285, -1.46356961, -1.38728821, -1.34681669, -1.4375068 ,\n",
       "        -1.34406208, -1.38347414, -1.43602355, -1.39131417, -1.45149172,\n",
       "        -1.4258527 , -1.3552924 , -1.41335102, -1.45339876, -1.40996074,\n",
       "        -1.46929072, -1.46653611, -1.44958469, -1.44788955, -1.41356292,\n",
       "        -1.38919525, -1.40402774, -1.43030245, -1.40487531, -1.4434398 ,\n",
       "        -1.2817656 , -1.42733595, -1.44110898, -1.45127983, -1.42225052,\n",
       "        -1.42394566, -1.39300932, -1.4023326 , -1.39576392, -1.39957799,\n",
       "        -1.33198419, -1.43729491, -1.33728151, -1.31566845, -1.36228486,\n",
       "        -1.45149172, -1.40127313, -1.34618101, -1.31799927, -1.44810144,\n",
       "        -1.35910647, -1.45869608, -1.42458134, -1.36270865, -1.37393896,\n",
       "        -1.36567515, -1.25739793, -1.4258527 , -1.43326894, -1.45996744,\n",
       "        -1.34618101, -1.4082656 , -1.42203863, -1.4169532 , -1.45954365,\n",
       "        -1.35147833, -1.42203863, -1.46611233, -1.44852523, -1.39809474,\n",
       "        -1.35953026, -1.4169532 , -1.43983762, -1.30337867, -1.42394566,\n",
       "        -1.37330329, -1.36440379, -1.43814248, -1.44492305, -1.31397331,\n",
       "        -1.41631752, -1.36398   , -1.45170362, -1.46441718, -1.37987196,\n",
       "        -1.45276308, -1.38008386, -1.46674801, -1.37563411, -1.33219609,\n",
       "        -1.45318687, -1.45149172, -1.34469776, -1.42775973, -1.46759558,\n",
       "        -1.44386358, -1.31100681, -1.39089039, -1.39830664, -1.38877146,\n",
       "        -1.4521274 , -1.45276308, -1.37732925, -1.44598251, -1.42754784,\n",
       "        -1.39279742, -1.36800597, -1.44110898, -1.39131417, -1.45106794,\n",
       "        -1.45911986, -1.3641919 , -1.41970781, -1.37542221, -1.39788285,\n",
       "        -1.40614667, -1.36673461, -1.4169532 , -1.45551769, -1.45975554,\n",
       "        -1.29151267, -1.42542891, -1.43009055, -1.34914751, -1.45763662,\n",
       "        -1.43220948, -1.37076057, -1.43517598, -1.44407548, -1.4434398 ,\n",
       "        -1.38262657, -1.42818352, -1.39661149, -1.42097916, -1.43390462,\n",
       "        -1.45361065, -1.41313913, -1.4082656 , -1.31905873, -1.40762992,\n",
       "        -1.42966677, -1.41483427, -1.43263327, -1.46335772, -1.42161484,\n",
       "        -1.45890797, -1.45848419, -1.40423963, -1.46356961, -1.45848419,\n",
       "        -1.44195655, -1.45403444, -1.45763662, -1.33092473, -1.45276308]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([(X[0]-means[0])/stds[0],(X[1]-means[1])/stds[1],(X[2]-means[2])/stds[2]])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.hstack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'1 задание'.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1 = # Ваш код здесь\n",
    "print(round(answer1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.linalg.inv  # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Полученный результат, округленный до 3 знаков после запятой, является ответом на *'2 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2 = # Ваш код здесь\n",
    "print(round(answer2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения?\n",
    "Полученный результат, округленный до 3 знаков после запятой, является ответом на *'3 задание'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer3 = # Ваш код здесь\n",
    "print(round(answer3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    grad0 = # Ваш код здесь\n",
    "    grad1 = # Ваш код здесь\n",
    "    grad2 = # Ваш код здесь\n",
    "    grad3 = # Ваш код здесь\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- min_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        # Ваш код здесь\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = # Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Полученный результат, округленный до 3 знаков после запятой, является ответом на *'4 задание'*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer4 = # Ваш код здесь\n",
    "print(round(answer4, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
